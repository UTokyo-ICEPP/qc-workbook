
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>【課題】量子カーネルを使った新現象の分類 &#8212; 量子コンピューティング・ワークブック</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="ToffoliゲートとShorコード" href="toffoli_shor_code.html" />
    <link rel="prev" title="量子機械学習を使った新しい素粒子現象の探索" href="vqc_machine_learning.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/favicon.ico" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">量子コンピューティング・ワークブック</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="welcome.html">
   量子コンピューティング・ワークブックへようこそ！
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  量子コンピュータに触れる
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="chsh_inequality.html">
   CHSH不等式の破れを確認する
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="nonlocal_correlations.html">
   【課題】量子相関を調べる
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  量子回路を作る
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="circuit_from_scratch.html">
   単純な量子回路をゼロから書く
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="quantum_computation.html">
   【課題】アダマールテスト
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  量子コンピュータでの並列計算
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="extreme_simd.html">
   計算をする量子回路の実装
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dynamics_simulation.html">
   物理系を表現する
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="more_dynamics.html">
   【課題】量子ダイナミクスシミュレーション・続
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="addition_on_ibmq.html">
   【参考】足し算を実機で行う
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ショアのアルゴリズム
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="shor.html">
   素因数分解アルゴリズムを学習する
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="spectrum_estimation.html">
   【課題】位相推定によるスペクトル分解
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  グローバーのアルゴリズム
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="grover.html">
   データベース検索を行う
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="grover_number_light.html">
   【課題】ビット反転ボードの操作を見つける
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  変分法と変分量子固有値ソルバー
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="vqe.html">
   変分法と変分量子固有値ソルバー法を学習する
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="vqe_tracking.html">
   【課題】高エネルギー実験で生成された荷電粒子の飛跡を見つける
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  量子・古典ハイブリッド機械学習
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="vqc_machine_learning.html">
   量子機械学習を使った新しい素粒子現象の探索
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   【課題】量子カーネルを使った新現象の分類
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  演習
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="toffoli_shor_code.html">
   ToffoliゲートとShorコード
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  補足
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="prerequisites.html">
   実習の準備
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="python_intro.html">
   予備知識：Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="numerics.html">
   予備知識：数値表現
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="references.html">
   参考文献
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bibliography.html">
   文献一覧
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="_sources/qkc_machine_learning.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/qkc_machine_learning.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/UTokyo-ICEPP/qc-workbook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/UTokyo-ICEPP/qc-workbook/issues/new?title=Issue%20on%20page%20%2Fqkc_machine_learning.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/UTokyo-ICEPP/qc-workbook/master?urlpath=lab/tree/qkc_machine_learning.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#q-kernel">
   量子カーネル
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#q-kernel-imp">
     量子カーネルの評価
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#svm">
   サポートベクターマシン
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     2クラス線形分離問題
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     双対形式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     カーネル行列との関係
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#qsvm-imp">
   素粒子探索への応用
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#problem1">
     問題1
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#problem2">
     問題2
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>【課題】量子カーネルを使った新現象の分類</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#q-kernel">
   量子カーネル
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#q-kernel-imp">
     量子カーネルの評価
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#svm">
   サポートベクターマシン
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     2クラス線形分離問題
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     双対形式
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     カーネル行列との関係
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#qsvm-imp">
   素粒子探索への応用
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#problem1">
     問題1
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#problem2">
     問題2
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="id1">
<h1>【課題】量子カーネルを使った新現象の分類<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p>これまで、量子・古典ハイブリッドアルゴリズムの一つである<a class="reference internal" href="vqc_machine_learning.html"><span class="doc">量子回路学習</span></a>の手法を使って、素粒子物理での新粒子探索が可能かを見てきました。ここでは、<strong>量子機械学習</strong>の別の手法として、<strong>量子カーネル</strong>を用いた分類を考えてみます。特に、量子カーネルを活用した<strong>サポートベクターマシン</strong>の手法<span id="id2">[<a class="reference internal" href="bibliography.html#id25" title="Vojtěch Havlíček, Antonio D. Córcoles, Kristan Temme, Aram W. Harrow, Abhinav Kandala, Jerry M. Chow, and Jay M. Gambetta. Supervised learning with quantum-enhanced feature spaces. Nature, 567(7747):209–212, 2019. URL: https://doi.org/10.1038/s41586-019-0980-2, doi:10.1038/s41586-019-0980-2.">HavlivcekCorcolesT+19</a>]</span>を使って、同じ新粒子探索の問題に取り組みます。</p>
<div class="contents local topic" id="id3">
<p class="topic-title">目次</p>
<ul class="simple">
<li><p><a class="reference internal" href="#q-kernel" id="id13">量子カーネル</a></p>
<ul>
<li><p><a class="reference internal" href="#q-kernel-imp" id="id14">量子カーネルの評価</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#svm" id="id15">サポートベクターマシン</a></p>
<ul>
<li><p><a class="reference internal" href="#id7" id="id16">2クラス線形分離問題</a></p></li>
<li><p><a class="reference internal" href="#id8" id="id17">双対形式</a></p></li>
<li><p><a class="reference internal" href="#id9" id="id18">カーネル行列との関係</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#qsvm-imp" id="id19">素粒子探索への応用</a></p>
<ul>
<li><p><a class="reference internal" href="#problem1" id="id20">問題1</a></p></li>
<li><p><a class="reference internal" href="#problem2" id="id21">問題2</a></p></li>
</ul>
</li>
</ul>
</div>
<p><span class="math notranslate nohighlight">\(\newcommand{\ket}[1]{| #1 \rangle}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\expval}[3]{\langle #1 | #2 | #3 \rangle}\)</span></p>
<div class="section" id="q-kernel">
<span id="id4"></span><h2><a class="toc-backref" href="#id13">量子カーネル</a><a class="headerlink" href="#q-kernel" title="Permalink to this headline">¶</a></h2>
<p>変分量子回路を使った量子回路学習では、</p>
<div class="math notranslate nohighlight">
\[
U_{\text{in}}(x_i) = \prod_j R_j^Z(\cos^{-1}(x^2))R_j^Y(\sin^{-1}(x))
\]</div>
<p>と定義した特徴量マップ<span class="math notranslate nohighlight">\(U_{\text{in}}(x_i)\)</span>を考えました。それを初期状態<span class="math notranslate nohighlight">\(\ket{0}^{\otimes n}\)</span>に適用することで、入力データから<span class="math notranslate nohighlight">\(\ket{\phi(x_i)}=U_{\text{in}}(x_i)\ket{0}^{\otimes n}\)</span>という量子状態を作りました。<strong>量子カーネル</strong>とは、この状態の内積<span class="math notranslate nohighlight">\(\langle\phi(x_j)|\phi(x_i)\rangle\)</span>（の絶対値2乗）</p>
<div class="math notranslate nohighlight">
\[
K(x_i,x_j):=|\langle\phi(x_j)|\phi(x_i)\rangle|^2=|\langle0^{\otimes n}|U_{\text{in}}^\dagger(x_j)U_{\text{in}}(x_i)|0^{\otimes n}\rangle|^2
\]</div>
<p>として定義される量です。量子カーネルの物理的な意味ですが、内積というものが表す通り、<span class="math notranslate nohighlight">\(\ket{\phi(x_i)}\)</span>と<span class="math notranslate nohighlight">\(\ket{\phi(x_j)}\)</span>の「近さ」あるいは「重なり具合」を表していると解釈できます。</p>
<div class="section" id="q-kernel-imp">
<span id="id5"></span><h3><a class="toc-backref" href="#id14">量子カーネルの評価</a><a class="headerlink" href="#q-kernel-imp" title="Permalink to this headline">¶</a></h3>
<p>量子カーネルを求めるためには、学習データの全てのペア<span class="math notranslate nohighlight">\(\{x_i,x_j\}\)</span>に対して、<span class="math notranslate nohighlight">\(K(x_i,x_j)=|\langle\phi(x_j)|\phi(x_i)\rangle|^2\)</span>を計算する必要があります。ここで「カーネルトリック」という言葉がよく使われますが、ヒルベルト空間での座標変数に明示的に依存しない形で<span class="math notranslate nohighlight">\(K(x_i,x_j)\)</span>を計算するために、以下のような量子回路を考えます。</p>
<a class="reference internal image-reference" href="_images/qke_circuit.png"><img alt="qke_circuit" class="align-center" src="_images/qke_circuit.png" style="width: 700px;" /></a>
<p>この回路に入力データ<span class="math notranslate nohighlight">\(x_i\)</span>と<span class="math notranslate nohighlight">\(x_j\)</span>をエンコードして、回路の出力状態を<span class="math notranslate nohighlight">\(Z\)</span>基底で測定するとします。カーネルの定義式から明らかなように、その時に全ての量子ビットが0になる（<span class="math notranslate nohighlight">\(0^n\)</span>ビット列が出てくる）確率が<span class="math notranslate nohighlight">\(K(x_i,x_j)\)</span>の評価値を与えてくれます。これを全てのペアに対して繰り返し実行し、カーネル行列の要素を決めていくことになるわけです。<span class="math notranslate nohighlight">\(0^n\)</span>ビット列測定によってカーネルを決めるため、量子回路の測定回数<span class="math notranslate nohighlight">\(N\)</span>に対して<span class="math notranslate nohighlight">\({\cal O}(1/\sqrt{N})\)</span>程度の誤差がついてしまうのは仕方ないところです。</p>
</div>
</div>
<div class="section" id="svm">
<span id="id6"></span><h2><a class="toc-backref" href="#id15">サポートベクターマシン</a><a class="headerlink" href="#svm" title="Permalink to this headline">¶</a></h2>
<p>上までのステップでカーネル行列が得られましたが、次にこのカーネル行列をサポートベクターマシンと呼ばれる手法に取り入れて、2クラスのデータ分類を行なってみます。</p>
<div class="section" id="id7">
<h3><a class="toc-backref" href="#id16">2クラス線形分離問題</a><a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>まず、2クラスの線形分離問題とはどういうものかを見ていきます。サンプル数<span class="math notranslate nohighlight">\(N\)</span>の学習データを<span class="math notranslate nohighlight">\(\{(\mathbf{X}_i,y_i)\}\:(i=1,\ldots,N)\)</span>とし、<span class="math notranslate nohighlight">\(\mathbf{X}_i \in \mathbb{R}^d\)</span>をインプット、<span class="math notranslate nohighlight">\(y_i\in\{+1,-1\}\)</span>をラベルと呼びます。分離問題とは、インプットの分布する空間<span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span>に境界を定義し、ラベルの値が<span class="math notranslate nohighlight">\(+1\)</span>であるデータ点が属する領域と<span class="math notranslate nohighlight">\(-1\)</span>であるデータ点が属する領域に分けることを指します。そして、その境界が超平面である場合を線形分離と呼びます。ここで超平面とは、ある<span class="math notranslate nohighlight">\(\mathbf{w}\in\mathbb{R}^d, b \in \mathbb{R}\)</span>に対して集合</p>
<div class="math notranslate nohighlight">
\[
\{\mathbf{X}| \mathbf{X} \in \mathbb{R}^d, \: \mathbf{w}\cdot\mathbf{X}+b=0\}
\]</div>
<p>を指します。ベクトル<span class="math notranslate nohighlight">\(\mathbf{w}\)</span>はこの超平面に直交し、そのノルムを<span class="math notranslate nohighlight">\(\lVert \mathbf{w} \rVert\)</span>と書くと、<span class="math notranslate nohighlight">\(b/\lVert \mathbf{w} \rVert\)</span>がこの超平面と原点との符号付き距離（<span class="math notranslate nohighlight">\(\mathbf{w}\)</span>の方向が正）に対応します。</p>
<p>超平面というのはシンプルであるがゆえに特殊な集合なので、学習データの分布のしかたによっては、超平面では分離できないケースもあり得ます。そのような分離が可能であるということは、</p>
<div class="math notranslate nohighlight" id="equation-linear-separation">
<span class="eqno">(24)<a class="headerlink" href="#equation-linear-separation" title="Permalink to this equation">¶</a></span>\[S_i(\mathbf{w}, b) := y_i(\mathbf{w}\cdot\mathbf{X}_i+b) \geq 1,\:\:\:\forall i=1,\ldots,N\]</div>
<p>を満たす<span class="math notranslate nohighlight">\((\mathbf{w},b)\)</span>が存在することと等価です。この式の解釈ですが、括弧の中身<span class="math notranslate nohighlight">\(\mathbf{w} \cdot \mathbf{X}_i + b\)</span>はデータ点<span class="math notranslate nohighlight">\(X_i\)</span>と超平面<span class="math notranslate nohighlight">\((\mathbf{w}, b)\)</span>との符号付き距離の<span class="math notranslate nohighlight">\(\lVert \mathbf{w} \rVert\)</span>倍で、それに<span class="math notranslate nohighlight">\(y_i\)</span>をかけた結果が1よりも大きいということは、<span class="math notranslate nohighlight">\(y_i=1\)</span>のデータ点が超平面について正の領域、<span class="math notranslate nohighlight">\(y_i=-1\)</span>のデータ点が負の領域にあり、かつどの点も超平面から<span class="math notranslate nohighlight">\(1/\lVert \mathbf{w} \rVert\)</span>以上離れているということを意味します。</p>
<p>さて、機械学習の目的は、学習データを元に何らかのモデルを作り、それを使って未知のインプットについて予言をすることにあります。今の分離問題においては、<span class="math notranslate nohighlight">\((\mathbf{w}, b)\)</span>がモデルにあたり、未知インプット<span class="math notranslate nohighlight">\(X\)</span>についてのラベル<span class="math notranslate nohighlight">\(y\)</span>の予言は</p>
<div class="math notranslate nohighlight" id="equation-test-data-label">
<span class="eqno">(25)<a class="headerlink" href="#equation-test-data-label" title="Permalink to this equation">¶</a></span>\[y = \mathrm{sgn}(\mathbf{w} \cdot \mathbf{X} + b)\]</div>
<p>（<span class="math notranslate nohighlight">\(\mathrm{sgn}(z)\)</span>は<span class="math notranslate nohighlight">\(z \in \mathbb{R}\)</span>の符号）で与えられます。このとき、学習データを最も「強く」2分割するようなモデルが、未知データについて最も精度の高い予言をできると仮定します。「強く」2分割するというのは、超平面とすべての学習データ点との距離<span class="math notranslate nohighlight">\(1/\lVert \mathbf{w} \rVert\)</span>が大きいことに相当します。線形分離が可能な学習データについて式<a class="reference internal" href="#equation-linear-separation">(24)</a>を満たす<span class="math notranslate nohighlight">\((\mathbf{w}, b)\)</span>は一意ではありませんが、その中で<span class="math notranslate nohighlight">\(\lVert \mathbf{w} \rVert\)</span>が最も小さくなるものが、最適なモデルということになります。</p>
<p>線形分離ができないような学習データについても、これと同じような発想で「できる限り」分離するという問題を考えることができます。この場合、学習とは<span class="math notranslate nohighlight">\(\lVert \mathbf{w} \rVert\)</span>ができるだけ小さく、かつ<span class="math notranslate nohighlight">\(\sum_{i} S_i(\mathbf{w}, b)\)</span>ができるだけ大きくなるような<span class="math notranslate nohighlight">\(\mathbf{w}\)</span>と<span class="math notranslate nohighlight">\(b\)</span>を探すことに相当し、以下の目的関数</p>
<div class="math notranslate nohighlight" id="equation-primal-1">
<span class="eqno">(26)<a class="headerlink" href="#equation-primal-1" title="Permalink to this equation">¶</a></span>\[f(\mathbf{w}, b) = \frac{1}{2} \lVert \mathbf{w} \rVert^2 + C \sum_{i=1}^{N} \mathrm{max}\left(0, 1 - S_i(\mathbf{w}, b)\right)\]</div>
<p>の最小化で達成されます。ここで、係数<span class="math notranslate nohighlight">\(C&gt;0\)</span>は、二つの目的のうちどちらをどれだけ優先するかを調整する「ハイパーパラメータ」です。第二項では<span class="math notranslate nohighlight">\(\mathrm{max}\)</span>関数で<span class="math notranslate nohighlight">\(S_i\)</span>の値が1以上になる（超平面から十分離れている）データ点を無視しています。無視されていない、つまり分離超平面付近にあったり誤って分類されたりしたデータ点インプット<span class="math notranslate nohighlight">\(\{\mathbf{X}_i | S_i &lt; 1\}\)</span>のことを「サポートベクター」と呼びます。どのデータ点がサポートベクターとなるかは<span class="math notranslate nohighlight">\(\mathbf{w}\)</span>と<span class="math notranslate nohighlight">\(b\)</span>の値によりますが、一度<span class="math notranslate nohighlight">\(f\)</span>を最小化するパラメータ値が決まれば、未知インプットについての予言には、対応するサポートベクターのみが使用されます（どのように使われるかは後述します）。このような機械学習モデルをサポートベクターマシンと呼びます。</p>
</div>
<div class="section" id="id8">
<h3><a class="toc-backref" href="#id17">双対形式</a><a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>次に、この最適化問題（主形式）の「双対問題」を見てみましょう。双対は、最適化問題に拘束条件を導入したラグランジアンを定義し、その停留点での値を未定定数の関数として表現し直すことで得られます。拘束条件の導入にはラグランジュの未定乗数法の拡張であるところのKarush-Kuhn-Tucker (KKT)の手法を用います。未定乗数法は拘束条件が等式で表されるときのみ使えるのに対し、KKT条件は不等式拘束条件にも対応します。</p>
<p>具体的には、まず式<a class="reference internal" href="#equation-primal-1">(26)</a>を<span class="math notranslate nohighlight">\(\mathrm{max}\)</span>関数を使わずに、パラメータ<span class="math notranslate nohighlight">\(\xi_i\)</span>を導入して次の形に書き換えます。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
F(\mathbf{w}, b, \{\xi_i\}) &amp; = \frac{1}{2} \lVert \mathbf{w} \rVert^2 + C \sum_{i=1}^{N} \xi_i \\
\text{with} &amp; \: \xi_i \geq 1 - S_i, \: \xi_i \geq 0 \quad \forall i
\end{align}
\end{split}\]</div>
<p>下行の拘束条件に従って<span class="math notranslate nohighlight">\(F\)</span>を最小化する<span class="math notranslate nohighlight">\(\mathbf{w}, b, \{\xi_i\}\)</span>が見つかったとき、<span class="math notranslate nohighlight">\(f\)</span>も最小化されることを確かめてください。</p>
<p>この最適化問題のラグランジアンは、非負の未定定数<span class="math notranslate nohighlight">\(\{\alpha_i\}\)</span>と<span class="math notranslate nohighlight">\(\{\beta_i\}\)</span>を導入して</p>
<div class="math notranslate nohighlight" id="equation-lagrangian">
<span class="eqno">(27)<a class="headerlink" href="#equation-lagrangian" title="Permalink to this equation">¶</a></span>\[L(\mathbf{w}, b, \{\xi_i\}; \{\alpha_i\}, \{\beta_i\}) = \frac{1}{2} \lVert \mathbf{w} \rVert^2 + C \sum_{i=1}^{N} \xi_i - \sum_{i=1}^{N} \alpha_i \left(\xi_i + S_i(\mathbf{w}, b) - 1\right) - \sum_{i=1}^{N} \beta_i \xi_i\]</div>
<p>で与えられます。停留点では</p>
<div class="math notranslate nohighlight" id="equation-stationarity">
<span class="eqno">(28)<a class="headerlink" href="#equation-stationarity" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
\frac{\partial L}{\partial \mathbf{w}} &amp; = \mathbf{w} - \sum_i \alpha_i y_i \mathbf{X}_i = 0 \\
\frac{\partial L}{\partial b} &amp; = -\sum_i \alpha_i y_i = 0 \\
\frac{\partial L}{\partial \xi_i} &amp; = C - \alpha_i - \beta_i = 0
\end{align}\end{split}\]</div>
<p>が成り立つので、式<a class="reference internal" href="#equation-lagrangian">(27)</a>にこれらの関係を代入すると、双対目的関数</p>
<div class="math notranslate nohighlight" id="equation-dual">
<span class="eqno">(29)<a class="headerlink" href="#equation-dual" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
G(\{\alpha_i\}) &amp; = \sum_{i} \alpha_i - \frac{1}{2} \sum_{ij} \alpha_i \alpha_j y_i y_j \mathbf{X}_i \cdot \mathbf{X}_j \\
\text{with} &amp; \sum_i \alpha_i y_i = 0, \: 0 \leq \alpha_i \leq C \quad \forall i
\end{align}\end{split}\]</div>
<p>が得られます。双対問題は、この<span class="math notranslate nohighlight">\(G\)</span>を最大化する<span class="math notranslate nohighlight">\(\{\alpha_i\}\)</span>を見つける問題となります。また、主形式の最適解<span class="math notranslate nohighlight">\(\mathbf{w}^*, b^*, \{\xi^*_i\}\)</span>と双対問題の最適解<span class="math notranslate nohighlight">\(\{\alpha^*_i\}\)</span>との間に</p>
<div class="math notranslate nohighlight" id="equation-complementarity">
<span class="eqno">(30)<a class="headerlink" href="#equation-complementarity" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
\alpha^*_i (\xi^*_i + S_i(\mathbf{w}^*, b^*) - 1) &amp; = 0 \\
\beta^*_i \xi^*_i = (C - \alpha^*_i) \xi^*_i &amp; = 0
\end{align}\end{split}\]</div>
<p>という関係（相補性条件）が成り立ちます。</p>
</div>
<div class="section" id="id9">
<h3><a class="toc-backref" href="#id18">カーネル行列との関係</a><a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>ここまで来てもカーネル行列とサポートベクターによる線形分離は一見無関係に思えますが、双対形式にヒントがあります。式<a class="reference internal" href="#equation-dual">(29)</a>に現れる<span class="math notranslate nohighlight">\(\mathbf{X}_i \cdot \mathbf{X}_j\)</span>はインプット空間を<span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span>としたときのインプットベクトル同士の内積です。しかし、双対形式ではパラメータ<span class="math notranslate nohighlight">\(\mathbf{w}\)</span>が現れないので、<span class="math notranslate nohighlight">\(\mathbf{X}_i\)</span>が何か他の線形空間<span class="math notranslate nohighlight">\(V\)</span>の元であるとしても問題として成立します。さらに、実はそもそもこの部分がベクトルの内積である必要すらありません。インプットを何か（線形とは限らない）空間<span class="math notranslate nohighlight">\(D\)</span>の元<span class="math notranslate nohighlight">\(x_i\)</span>とし、<span class="math notranslate nohighlight">\(D\)</span>の二つの元<span class="math notranslate nohighlight">\(x_i\)</span>と<span class="math notranslate nohighlight">\(x_j\)</span>の間の何らかの「距離」を表す関数</p>
<div class="math notranslate nohighlight">
\[
K: \: D \times D \to \mathbb{R}
\]</div>
<p>があるとします。すると、最も一般に、サポートベクターマシンとは、学習データ<span class="math notranslate nohighlight">\(\{(x_i, y_i) \in D \times \mathbb{R}\} \: (i=1,\ldots,N)\)</span>について目的関数</p>
<div class="math notranslate nohighlight" id="equation-dual-kernel">
<span class="eqno">(31)<a class="headerlink" href="#equation-dual-kernel" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
G(\{\alpha_i\}) &amp; = \sum_{i} \alpha_i - \frac{1}{2} \sum_{ij} \alpha_i \alpha_j y_i y_j K(x_i, x_j) \\
\text{with} &amp; \sum_i \alpha_i y_i = 0, \: \alpha_i \geq 0 \quad \forall i
\end{align}\end{split}\]</div>
<p>を最大化する問題として定義できます。</p>
<p>上で定義したカーネル行列は、まさにこの距離関数<span class="math notranslate nohighlight">\(K(x_i, x_j)\)</span>に相当します。これでやっとカーネル行列をどうサポートベクターマシンに取り入れるのかが明らかになりました。</p>
<p>さて、式<a class="reference internal" href="#equation-complementarity">(30)</a>の相補性条件をよく眺めると、<span class="math notranslate nohighlight">\(\alpha^*_i, \xi^*_i, S^*_i\)</span> (<span class="math notranslate nohighlight">\(S^*_i := S_i(\mathbf{w}^*, b^*)\)</span>)について</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\alpha^*_i = C, \xi^*_i = 1 - S^*_i \geq 0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha^*_i = 0, \xi^*_i = 0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(0 &lt; \alpha^*_i &lt; C, \xi^*_i = 0, S^*_i = 1\)</span></p></li>
</ul>
<p>の3通りの値の組み合わせしかないことがわかります。特に、<span class="math notranslate nohighlight">\(S^*_i &gt; 1\)</span>のとき<span class="math notranslate nohighlight">\(\alpha^*_i = 0\)</span>となります。すると、式<a class="reference internal" href="#equation-dual-kernel">(31)</a>における和はすべて<span class="math notranslate nohighlight">\(S^*_i \leq 1\)</span>であるような<span class="math notranslate nohighlight">\(i\)</span>、つまりサポートベクターについてのみ取ればいいことがわかります。</p>
<p>最後に、カーネル形式で表したサポートベクターマシンで学習を行った（<span class="math notranslate nohighlight">\(G\)</span>を最大化する<span class="math notranslate nohighlight">\(\{\alpha_i\}\)</span>を見つけた）ときに、未知データ<span class="math notranslate nohighlight">\(x\)</span>に対するラベルの予言がどう与えられるかを考えます。元の形式（主形式と呼びます）ではラベルが式<a class="reference internal" href="#equation-test-data-label">(25)</a>で与えられますが、ここに式<a class="reference internal" href="#equation-stationarity">(28)</a>の第一式を代入すると、</p>
<div class="math notranslate nohighlight">
\[
y = \mathrm{sgn}\left(\sum_{i\in \mathrm{s.v.}} \alpha^*_i y_i K(x_i, x) + b^*\right)
\]</div>
<p>となります。ここで<span class="math notranslate nohighlight">\(\alpha^*_i\)</span>は<span class="math notranslate nohighlight">\(G\)</span>を最大化する最適パラメータで、<span class="math notranslate nohighlight">\(i\)</span>についての和はサポートベクターについてのみ取っています。パラメータ<span class="math notranslate nohighlight">\(b\)</span>の値の最適値<span class="math notranslate nohighlight">\(b^*\)</span>は、<span class="math notranslate nohighlight">\(S^*_j = 1\)</span>となるデータ点<span class="math notranslate nohighlight">\(j\)</span>について</p>
<div class="math notranslate nohighlight">
\[
y_j \left(\sum_{i\in \mathrm{s.v.}} \alpha^*_i y_i K(x_i, x_j) + b^*\right)= 1
\]</div>
<p>を解くことで得られます。</p>
</div>
</div>
<div class="section" id="qsvm-imp">
<span id="id10"></span><h2><a class="toc-backref" href="#id19">素粒子探索への応用</a><a class="headerlink" href="#qsvm-imp" title="Permalink to this headline">¶</a></h2>
<p>それでは、<a class="reference internal" href="vqc_machine_learning.html"><span class="doc">ここ</span></a>で考えた素粒子現象の探索問題に、量子サポートベクターマシンを応用してみましょう。</p>
<p>データセットの準備は同じです。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="kn">from</span> <span class="nn">qiskit</span> <span class="kn">import</span> <span class="n">QuantumCircuit</span><span class="p">,</span> <span class="n">transpile</span>
<span class="kn">from</span> <span class="nn">qiskit.circuit</span> <span class="kn">import</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">ParameterVector</span>
<span class="kn">from</span> <span class="nn">qiskit.circuit.library</span> <span class="kn">import</span> <span class="n">TwoLocal</span><span class="p">,</span> <span class="n">ZFeatureMap</span><span class="p">,</span> <span class="n">ZZFeatureMap</span>
<span class="kn">from</span> <span class="nn">qiskit.primitives</span> <span class="kn">import</span> <span class="n">Sampler</span>
<span class="kn">from</span> <span class="nn">qiskit.quantum_info</span> <span class="kn">import</span> <span class="n">SparsePauliOp</span>
<span class="kn">from</span> <span class="nn">qiskit_aer</span> <span class="kn">import</span> <span class="n">AerSimulator</span>
<span class="kn">from</span> <span class="nn">qiskit_machine_learning.kernels</span> <span class="kn">import</span> <span class="n">FidelityQuantumKernel</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ファイルから変数を読み出す</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/SUSY_1K.csv&quot;</span><span class="p">,</span>
                 <span class="n">names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;isSignal&#39;</span><span class="p">,</span> <span class="s1">&#39;lep1_pt&#39;</span><span class="p">,</span> <span class="s1">&#39;lep1_eta&#39;</span><span class="p">,</span> <span class="s1">&#39;lep1_phi&#39;</span><span class="p">,</span> <span class="s1">&#39;lep2_pt&#39;</span><span class="p">,</span> <span class="s1">&#39;lep2_eta&#39;</span><span class="p">,</span>
                        <span class="s1">&#39;lep2_phi&#39;</span><span class="p">,</span> <span class="s1">&#39;miss_ene&#39;</span><span class="p">,</span> <span class="s1">&#39;miss_phi&#39;</span><span class="p">,</span> <span class="s1">&#39;MET_rel&#39;</span><span class="p">,</span> <span class="s1">&#39;axial_MET&#39;</span><span class="p">,</span> <span class="s1">&#39;M_R&#39;</span><span class="p">,</span> <span class="s1">&#39;M_TR_2&#39;</span><span class="p">,</span>
                        <span class="s1">&#39;R&#39;</span><span class="p">,</span> <span class="s1">&#39;MT2&#39;</span><span class="p">,</span> <span class="s1">&#39;S_R&#39;</span><span class="p">,</span> <span class="s1">&#39;M_Delta_R&#39;</span><span class="p">,</span> <span class="s1">&#39;dPhi_r_b&#39;</span><span class="p">,</span> <span class="s1">&#39;cos_theta_r1&#39;</span><span class="p">))</span>

<span class="c1"># 学習に使う変数の数</span>
<span class="n">feature_dim</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># dimension of each data point</span>

<span class="c1"># 3, 5, 7変数の場合に使う変数のセット</span>
<span class="k">if</span> <span class="n">feature_dim</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
    <span class="n">selected_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;lep1_pt&#39;</span><span class="p">,</span> <span class="s1">&#39;lep2_pt&#39;</span><span class="p">,</span> <span class="s1">&#39;miss_ene&#39;</span><span class="p">]</span>
<span class="k">elif</span> <span class="n">feature_dim</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
    <span class="n">selected_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;lep1_pt&#39;</span><span class="p">,</span> <span class="s1">&#39;lep2_pt&#39;</span><span class="p">,</span> <span class="s1">&#39;miss_ene&#39;</span><span class="p">,</span> <span class="s1">&#39;M_TR_2&#39;</span><span class="p">,</span> <span class="s1">&#39;M_Delta_R&#39;</span><span class="p">]</span>
<span class="k">elif</span> <span class="n">feature_dim</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span>
    <span class="n">selected_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;lep1_pt&#39;</span><span class="p">,</span> <span class="s1">&#39;lep1_eta&#39;</span><span class="p">,</span> <span class="s1">&#39;lep2_pt&#39;</span><span class="p">,</span> <span class="s1">&#39;lep2_eta&#39;</span><span class="p">,</span> <span class="s1">&#39;miss_ene&#39;</span><span class="p">,</span> <span class="s1">&#39;M_TR_2&#39;</span><span class="p">,</span> <span class="s1">&#39;M_Delta_R&#39;</span><span class="p">]</span>

<span class="c1"># 学習に使う事象数: trainは訓練用サンプル、testはテスト用サンプル</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="mi">20</span>

<span class="n">df_sig</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">isSignal</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="n">selected_features</span><span class="p">]</span>
<span class="n">df_bkg</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">isSignal</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="n">selected_features</span><span class="p">]</span>

<span class="c1"># サンプルの生成</span>
<span class="n">df_sig_train</span> <span class="o">=</span> <span class="n">df_sig</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span><span class="n">train_size</span><span class="p">]</span>
<span class="n">df_bkg_train</span> <span class="o">=</span> <span class="n">df_bkg</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span><span class="n">train_size</span><span class="p">]</span>
<span class="n">df_sig_test</span> <span class="o">=</span> <span class="n">df_sig</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">train_size</span><span class="p">:</span><span class="n">train_size</span> <span class="o">+</span> <span class="n">test_size</span><span class="p">]</span>
<span class="n">df_bkg_test</span> <span class="o">=</span> <span class="n">df_bkg</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">train_size</span><span class="p">:</span><span class="n">train_size</span> <span class="o">+</span> <span class="n">test_size</span><span class="p">]</span>
<span class="c1"># 最初のtrain_size事象がSUSY粒子を含む信号事象、残りのtrain_size事象がSUSY粒子を含まない背景事象</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">df_sig_train</span><span class="p">,</span> <span class="n">df_bkg_train</span><span class="p">])</span>
<span class="c1"># 最初のtest_size事象がSUSY粒子を含む信号事象、残りのtest_size事象がSUSY粒子を含まない背景事象</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">df_sig_test</span><span class="p">,</span> <span class="n">df_bkg_test</span><span class="p">])</span>

<span class="c1"># ラベル（信号事象では第1次元の第0要素が1、背景事象では第1次元の第1要素が1）</span>
<span class="n">train_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">train_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="n">train_label</span><span class="p">[:</span><span class="n">train_size</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">test_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">train_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="n">test_label</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">mms</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">norm_train_data</span> <span class="o">=</span> <span class="n">mms</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">norm_test_data</span> <span class="o">=</span> <span class="n">mms</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="problem1">
<span id="id11"></span><h3><a class="toc-backref" href="#id20">問題1</a><a class="headerlink" href="#problem1" title="Permalink to this headline">¶</a></h3>
<p>各自特徴量マップを選び、<code class="docutils literal notranslate"><span class="pre">feature_map</span></code>という変数名の量子回路オブジェクトとして実装してください。<a class="reference internal" href="vqc_machine_learning.html"><span class="doc">量子機械学習を使った新しい素粒子現象の探索</span></a>のように<code class="docutils literal notranslate"><span class="pre">ZFeatureMap</span></code>や<code class="docutils literal notranslate"><span class="pre">ZZFeatureMap</span></code>などのクラスを利用しても、自分で空の<code class="docutils literal notranslate"><span class="pre">QuantumCircuit</span></code>オブジェクトを作り、<code class="docutils literal notranslate"><span class="pre">Parameter</span></code>や<code class="docutils literal notranslate"><span class="pre">ParameterVector</span></code>を使って「手で」回路を書いても構いません。</p>
<p>使用する量子ビットの数も原則自由ですが、後で利用する<code class="docutils literal notranslate"><span class="pre">FidelityQuantumKernel</span></code>クラスはインプットの変数の数と量子ビット数が等しいときに一番うまく動作するようです。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">##################</span>
<span class="c1">### EDIT BELOW ###</span>
<span class="c1">##################</span>

<span class="c1">#回路をスクラッチから書く場合</span>
<span class="n">input_features</span> <span class="o">=</span> <span class="n">ParameterVector</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">feature_dim</span><span class="p">)</span>
<span class="n">num_qubits</span> <span class="o">=</span> <span class="n">feature_dim</span>
<span class="n">feature_map</span> <span class="o">=</span> <span class="n">QuantumCircuit</span><span class="p">(</span><span class="n">num_qubits</span><span class="p">)</span>
<span class="c1"># ...</span>

<span class="c1">##################</span>
<span class="c1">### EDIT ABOVE ###</span>
<span class="c1">##################</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="problem2">
<span id="id12"></span><h3><a class="toc-backref" href="#id21">問題2</a><a class="headerlink" href="#problem2" title="Permalink to this headline">¶</a></h3>
<p>問題1で決めた特徴量マップからカーネル行列要素を計算するための<code class="docutils literal notranslate"><span class="pre">manual_kernel</span></code>という変数名の量子回路を作ってください。Qiskitにはこれを自動でやってくれるAPI（<code class="docutils literal notranslate"><span class="pre">FidelityQuantumKernel</span></code>クラス）が準備されていますが、ここでは空の<code class="docutils literal notranslate"><span class="pre">QuantumCircuit</span></code>オブジェクトから始めて、上で決めた特徴量マップ回路からパラメータ付きの回路を作ってください。</p>
<p><strong>ヒント1</strong></p>
<p>QuantumCircuitオブジェクトに別のQuantumCircuitを貼り付けるには</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">circuit</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">another_circuit</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>とします。このとき<code class="docutils literal notranslate"><span class="pre">inplace=True</span></code>を忘れると、<code class="docutils literal notranslate"><span class="pre">compose</span></code>メソッドは<code class="docutils literal notranslate"><span class="pre">circuit</span></code>に<code class="docutils literal notranslate"><span class="pre">another_circuit</span></code>を貼り付ける代わりに新しい回路オブジェクトを返してしまいます。</p>
<p><strong>ヒント2</strong></p>
<p>QuantumCircuitには<code class="docutils literal notranslate"><span class="pre">inverse()</span></code>という、逆回路を返すメソッドが備わっています。</p>
<p><strong>ヒント3</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">manual_kernel</span></code>のパラメータセットに注意してください。<code class="docutils literal notranslate"><span class="pre">feature_map</span></code>やその単純なコピーから<code class="docutils literal notranslate"><span class="pre">manual_kernel</span></code>を作っただけでは、後者は前者に使われるパラメータしか持ちません。</p>
<p>回路のパラメータセットを別のパラメータセットに置き換える方法として、</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">current_parameters</span> <span class="o">=</span> <span class="n">circuit</span><span class="o">.</span><span class="n">parameters</span>
<span class="n">new_parameters</span> <span class="o">=</span> <span class="n">ParameterVector</span><span class="p">(</span><span class="s1">&#39;new_params&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">current_parameters</span><span class="p">))</span>
<span class="n">bind_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">current_parameters</span><span class="p">,</span> <span class="n">new_parameters</span><span class="p">))</span>
<span class="n">new_circuit</span> <span class="o">=</span> <span class="n">circuit</span><span class="o">.</span><span class="n">assign_parameters</span><span class="p">(</span><span class="n">bind_params</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>などがあります。この場合、<code class="docutils literal notranslate"><span class="pre">new_circuit</span></code>は<code class="docutils literal notranslate"><span class="pre">new_parameters</span></code>でパラメタライズされます。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">manual_kernel</span> <span class="o">=</span> <span class="n">QuantumCircuit</span><span class="p">(</span><span class="n">feature_map</span><span class="o">.</span><span class="n">num_qubits</span><span class="p">)</span>

<span class="c1">##################</span>
<span class="c1">### EDIT BELOW ###</span>
<span class="c1">##################</span>

<span class="c1">##################</span>
<span class="c1">### EDIT ABOVE ###</span>
<span class="c1">##################</span>

<span class="n">manual_kernel</span><span class="o">.</span><span class="n">measure_all</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>作った量子回路をシミュレータで実行して、全ての量子ビットで0を測定する確率<span class="math notranslate nohighlight">\(|\langle0^{\otimes n}|U_{\text{in}}^\dagger(x_1)U_{\text{in}}(x_0)|0^{\otimes n}\rangle|^2\)</span>を計算します。</p>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sampler</span> <span class="o">=</span> <span class="n">Sampler</span><span class="p">()</span>

<span class="n">first_two_inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">norm_train_data</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="n">job</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">manual_kernel</span><span class="p">,</span> <span class="n">parameter_values</span><span class="o">=</span><span class="n">first_two_inputs</span><span class="p">,</span> <span class="n">shots</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="c1"># quasi_dists[0]がmanual_kernelの測定結果のcountsから推定される確率分布</span>
<span class="n">fidelity</span> <span class="o">=</span> <span class="n">job</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">quasi_dists</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;|&lt;φ(x_0)|φ(x_1)&gt;|^2 = </span><span class="si">{</span><span class="n">fidelity</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>次に同じことを<code class="docutils literal notranslate"><span class="pre">FidelityQuantumKernel</span></code>クラスを利用して行います。</p>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># FidelityQuantumKernelは内部で勝手にSamplerインスタンスを作る</span>
<span class="n">q_kernel</span> <span class="o">=</span> <span class="n">FidelityQuantumKernel</span><span class="p">(</span><span class="n">feature_map</span><span class="o">=</span><span class="n">feature_map</span><span class="p">)</span>

<span class="n">bind_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">feature_map</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">norm_train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">feature_map_0</span> <span class="o">=</span> <span class="n">feature_map</span><span class="o">.</span><span class="n">bind_parameters</span><span class="p">(</span><span class="n">bind_params</span><span class="p">)</span>
<span class="n">bind_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">feature_map</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">norm_train_data</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">feature_map_1</span> <span class="o">=</span> <span class="n">feature_map</span><span class="o">.</span><span class="n">bind_parameters</span><span class="p">(</span><span class="n">bind_params</span><span class="p">)</span>

<span class="n">qc_circuit</span> <span class="o">=</span> <span class="n">q_kernel</span><span class="o">.</span><span class="n">fidelity</span><span class="o">.</span><span class="n">create_fidelity_circuit</span><span class="p">(</span><span class="n">feature_map_0</span><span class="p">,</span> <span class="n">feature_map_1</span><span class="p">)</span>
<span class="n">qc_circuit</span><span class="o">.</span><span class="n">decompose</span><span class="p">()</span><span class="o">.</span><span class="n">decompose</span><span class="p">()</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;mpl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">FidelityQuantumKernel</span></code>を使うと、カーネル行列を直接書き出して見ることも容易にできます。学習データから求めたカーネル行列と、学習データとテストデータから計算したカーネル行列をプロットしてみます。</p>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">matrix_train</span> <span class="o">=</span> <span class="n">q_kernel</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_vec</span><span class="o">=</span><span class="n">norm_train_data</span><span class="p">)</span>
<span class="n">matrix_test</span> <span class="o">=</span> <span class="n">q_kernel</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_vec</span><span class="o">=</span><span class="n">norm_test_data</span><span class="p">,</span> <span class="n">y_vec</span><span class="o">=</span><span class="n">norm_train_data</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asmatrix</span><span class="p">(</span><span class="n">matrix_train</span><span class="p">),</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;upper&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;training kernel matrix&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asmatrix</span><span class="p">(</span><span class="n">matrix_test</span><span class="p">),</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;upper&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Reds&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;validation kernel matrix&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>最後に、sklearnパッケージに実装されているサポートベクターマシンを使って分類を行います。量子回路学習の場合と同様に、データサイズや特徴量マップを変えるなどして分類精度がどう変わるか調べてみてください。</p>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">qc_svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">)</span> <span class="c1"># ハイパーパラメータ(C)のデフォルト値は1</span>
<span class="n">qc_svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">matrix_train</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>

<span class="n">train_score</span> <span class="o">=</span> <span class="n">qc_svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">matrix_train</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>
<span class="n">test_score</span> <span class="o">=</span> <span class="n">qc_svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">matrix_test</span><span class="p">,</span> <span class="n">test_label</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Precomputed kernel: Classification Train score: </span><span class="si">{</span><span class="n">train_score</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Precomputed kernel: Classification Test score:  </span><span class="si">{</span><span class="n">test_score</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>提出するもの</strong></p>
<ul class="simple">
<li><p>選んだ特徴量マップの説明とそのコード（問題１）</p></li>
<li><p>カーネル行列要素を計算するための量子回路のコードと、その回路を使って計算した<span class="math notranslate nohighlight">\(K(x_0, x_1)\)</span>の値（問題２）</p></li>
<li><p>この<a class="reference internal" href="vqc_machine_learning.html"><span class="doc">ワークブック</span></a>にある変分量子回路を使った量子機械学習との比較</p>
<ul>
<li><p>二つの方法を同じ条件（特徴量の変数、データサンプルのサイズ、特徴量マップ）で比較した時に、分類性能に対して何か系統的な違いは見えるでしょうか。特徴量やサンプルサイズを変えて比較するなどして、その振る舞いを自分なりに考察してみてください。</p></li>
<li><p>一方が他方に比べて系統的に分類性能が悪くなっている場合、どうすれば悪い方を改善できるでしょうか。サンプルサイズが小さい時には、どちらの方法でも過学習（テストデータでの分類性能が訓練データでの分類性能より悪くなる）の傾向が見えていると思います。過学習をできるだけ抑えながら、分類性能を改善する方法がないか、考察してみてください。</p></li>
</ul>
</li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "UTokyo-ICEPP/qc-workbook",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="vqc_machine_learning.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">量子機械学習を使った新しい素粒子現象の探索</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="toffoli_shor_code.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">ToffoliゲートとShorコード</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By 東京大学素粒子物理国際研究センター<br/>
    
        &copy; Copyright 2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>